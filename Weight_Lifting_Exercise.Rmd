---
title: "WEIGHT LIFTING EXERCISE DATA ANALYSIS"
author: "Korhan Tezel"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview
Using the data from devices such as Jawbone Up, Nike FuelBand, and Fitbit, which collect data of human body movement, we will try to identify how well the participants perform a barbell lift activity. Participants were asked to perform the same set of exercises correctly and incorrectly with accelerometers placed on the belt, forearm, and dumbbell. 

## Summary
The data is separated into training and test data sets by 70/30 ratio respectively. After separation, 3 models are used to predict the "classe" variable.

1) Random Forests: ran with 10-fold cross-validation

   This prediction model turned out pretty accurate when it was ran on the test data set.

2) Decision Tree:

   This prediction model is the least accurate one.

3) Gradient Boost with 10-fold cross-validation

   This prediction model is also pretty accurate when used on the test data set.

## Getting and Cleaning The Data
Data is downloaded through provided URLs. There are training and test data sets. All the missing values will be converted into NAs.Timestamp and username columns will be removed since they don't add any value to the analysis.
Character values in column new_window will be converted 1(for yes) and 0(for no). There are some columns with lots of missing values. These columns will be ignored since missing values makes certain models harder to run.
```{r getting_data, cache=TRUE}
# Reading and processing training data
trainData <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", na.strings=c("NA","NaN","","#DIV/0!"))
trainData_clean <- trainData[-c(1:5)]
trainData_clean$new_window <- ifelse(trainData_clean$new_window =="yes",1,0)
trainData_clean <- trainData_clean[,colSums(is.na(trainData_clean))==0]

# Reading and processing test data
testData <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", na.strings=c("NA","NaN","","#DIV/0!"))
testData_clean <- testData[-c(1:5)]
testData_clean$new_window <- ifelse(testData_clean$new_window =="yes",1,0)
testData_clean <- testData_clean[,colSums(is.na(testData_clean)) == 0]
```
## Exploratory Data Analysis
```{r data dimensions, message=FALSE}
dim(trainData_clean)
dim(testData_clean)

# Install necessary libraries for correlation plotting
if(!require("corrplot")) install.packages("corrplot"); library("corrplot")
mydata.cor = cor(trainData_clean[,-55], method=c("spearman"))
if(!require("Hmisc")) install.packages("Hmisc"); library("Hmisc")
palette = colorRampPalette(c("green", "white", "red")) (20)
heatmap(x = mydata.cor, col = palette, symm = TRUE)
```

Counting classe frequency.
```{r data_frequency, message=FALSE}
if(!require("plyr")) install.packages("plyr"); library("plyr")
count(trainData_clean, "classe")
```

# Partitioning the Data
```{r partitioning_data, message=FALSE}
if(!require("ggplot2")) install.packages("ggplot2"); library("ggplot2")
if(!require("caret")) install.packages("caret"); library("caret")
inTraining <- createDataPartition(trainData_clean$classe, p=0.7, list=FALSE)
training <- trainData_clean[inTraining,]
testing <- trainData_clean[-inTraining,]
```

# Building a Prediction Model
## Random Forests
Building a model with Random Forests is processor exhaustive; therefore, we will be using parallel processing to increase the performance and shorten the length of processing time. We are using 10-fold Cross-Validation. 
Step 1: Configure parallel processing
```{r parallel, message=FALSE}
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() -1)
registerDoParallel(cluster)
```

Step 2: Configure trainControl object
```{r trainControl_object, cache=TRUE}
fitControl <- trainControl(method = "cv", number = 10, allowParallel = TRUE)
```

Step 3: Develop training model
```{r random_forest, cache=TRUE}
fit <- train(classe ~., method="rf", data=trainData_clean, trControl = fitControl)
```

Step 4: De-register parellel processing cluster
```{r de-register_parallel, message=FALSE}
stopCluster(cluster)
registerDoSEQ()
```
Using predictive model on the testing data.
```{r testing_data}
pred <- predict(fit, testing)
```
Looking at the confusion matrix to see the accuracy of the predictive model on the testing data.
As it can be from the testing data, the model accurately predicts the classe variable in the testing data; however, we should be aware of an overfitting issue. We have another data set that we can use to test our model on. 
```{r rf_confusion_matrix}
conf <- confusionMatrix(pred, as.factor(testing$classe))
conf$table; conf$overall[1]
```

## Decisision Tree
```{r , message=FALSE}
if(!require("rattle")) install.packages("rattle"); library("rattle")
```
```{r decision_tree}
fit_rpart <- train(classe ~., method="rpart", data=training)
```

```{r pred2}
pred2 <- predict(fit_rpart, testing)
```
According to the confusion matrix, Decision Tree model is not a succesful prediction model.
```{r rf_confusion_matrix2}
conf2 <- confusionMatrix(pred2, as.factor(testing$classe))
conf2$table;conf2$overall[1]
```
## Gradient Boosting
```{r gbm, cache=TRUE}
fit_gbm <- train(classe ~ ., data=training, method="gbm", verbose=F, 
    trControl=trainControl(method="cv", number=2, allowParallel=T))
```

```{r pred3}
pred3 <- predict(fit_gbm, testing)
```

```{r conf3}
conf3 <- confusionMatrix(pred3, as.factor(testing$classe))
conf3$table; conf3$overall[1]
```

Both gradient boosting and Random Forests are a good predictor models for the test data set.